---
title: "Pilot Analysis"
author: "Howard Baek"
date: "6/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(scales)
library(factoextra)
library(raster)
library(tmap)
library(png)
library(gridExtra)
library(dendextend)
library(DescTools)
theme_set(theme_light())

source(file.path(here::here(), "R", "imgVectortoRaster.R"))
source(file.path(here::here(), "R", "dendIMG.R"))
source(file.path(here::here(), "R", "myheatmap.R"))
source(file.path(here::here(), "R", "desat.R"))
source(file.path(here::here(), "R", "kheatmap.R"))
source(file.path(here::here(), "R", "addIMGtopanel.R"))
source(file.path(here::here(), "R", "yearTable.R"))
source("../processCSV-tidyverse.R")
# Code to download data from ERDDAP servers is in data folder
```


## Re-run Eli talk analyses 

Latitude (42.625, 52.125) and Longitude (229.875, 236.625)

```{r}
# I downloaded the data using read_csv("https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg.csv?sst%5B(2010-01-01T12:00:00Z):(2021-06-01T12:00:00Z)%5D%5B(0.0)%5D%5B(42.625):(52.125)%5D%5B(229.875):(236.625)%5D&.draw=surface&.vars=longitude%7Clatitude%7Csst&.colorBar=%7C%7C%7C12%7C19%7C&.bgColor=0xffccccff")

# Raw data (last 10 years)
df_raw <- read_csv("pilot_data.csv")

# Processed data
df_processed <- df_raw %>% 
  # Get rid of miscellaneous zlev in first row
  slice(-1) %>% 
  # zlev is a column of zeroes, so get rid of that
  dplyr::select(-zlev) %>% 
  # Convert into date
  mutate(time = ymd_hms(time),
         # Extract out day so I can just filter for first day in each month
         day = day(time)) %>% 
  # filter for first day in each month
  filter(day == 1) %>% 
  dplyr::select(-day) %>% 
  # Set column names
  rename(date = time,
         lat = latitude,
         lon = longitude) %>% 
  # Convert date column to Date type
  mutate(date = as.Date(date),
         lat = as.numeric(lat),
         lon = as.numeric(lon),
         sst = as.numeric(sst))
 
```

```{r}
# Check if same n for each date
n.by.date <- tapply(df_processed$sst, df_processed$date, function(x){sum(is.na(x))})
if(any((n.by.date-n.by.date[1])!=0)) {
  stop("There's a problem. Should be same n for each date.")
} 

# Pivot Wider
df_wide <- df_processed %>% 
  pivot_wider(names_from = date, values_from = sst)

# which row are non-NA?
pos_loc <- which(!is.na(df_wide[,3]))

# Omit data and take transpose
df_clean <- df_wide %>% 
  # remove the rows that are NA
  na.omit()

# Take transpose of df_wide and df_clean to mimic output of processCSV-tidyverse.R
df_wide <- t(df_wide)
df_clean <- t(df_clean)

datalist <- list(dat = dat_wide, dat_clean = dat_clean, pos_loc = pos_loc)
```

```{r}
# Take out rows with lat, lon
image <- df_clean[c(-1,-2),]
# image_df %>% View()

# Create image_df_norm (X_norm in QuanSeminar.Rmd)
image_norm <- t(scale(t(image), scale=FALSE))
colnames(image_norm) <- colnames(X) <- paste0("p", 1:ncol(image_norm))
# image_norm is a 138 by 805 matrix
```


```{r}
round(image_norm[1:5, 1:10], digits=2)
```

```{r}
prcomp_pca <- prcomp(image_norm, scale = FALSE, center=FALSE)
prcomp_pca$rotation[,1] <- -1 * prcomp_pca$rotation[,1]
prcomp_pca$x[,1] <- -1 * prcomp_pca$x[,1]
# Store for use later
eigenimages <- t(prcomp_pca$rotation)
alpha <- prcomp_pca$x
```


```{r}
df <- data.frame(alpha,
                date = as.Date(rownames(image_norm)),
                year=as.integer(format(as.Date(rownames(image_norm)), "%Y")),
                mon=factor(format(as.Date(rownames(image_norm)), "%b"), levels = month.abb)
                )
df2 <- df %>% 
  pivot_longer(starts_with("PC"), names_to="PC", values_to="value")

df2 %>% count(PC)
```

```{r}
eigenimages <- t(prcomp_pca$rotation)
round(eigenimages[1:5, 1:10], digits=2)
```

```{r}
img_list <- imgVectortoRaster(eigenimages, datalist)$list
```

Error Message: 

> Error in centroid_images[, datalist$pos.loc] <- centers : 
  number of items to replace is not a multiple of replacement length